# Projet-MM-IA
How to leverage Mediapipe to estimate both facial and body landmarks. With that data we’ll then be able to build custom pose classification models that allow us to decode what a person might be saying with their body language with fine grain accuracy. Best of all, we can customise this to suit our own needs. If we wanted to extend this to perform drowsiness detection or extended pose classification with hand models we could! 

We’ll see how to:
1. Set up MediaPipe for Python 
2. Estimate Face and Body poses using our Webcam and OpenCV
3. Collect and process Joint Coordinates using Pandas
4. Train a custom Pose Classification model using Scikit-Learn
5. Decode Body Language in Real time
   
    Here are some examples:


 ![angry1](https://github.com/asmakhoualdia98/Projet-MM-IA/assets/89219090/0b23381c-c224-4bb2-ad57-b8ebc30122c8)
![neutral1](https://github.com/asmakhoualdia98/Projet-MM-IA/assets/89219090/0c7f4e35-6629-465b-9f98-10edbc85bad6)
![happy](https://github.com/asmakhoualdia98/Projet-MM-IA/assets/89219090/76eb78d0-fd0e-4bae-95b2-689e98a762d2)
![neutral](https://github.com/asmakhoualdia98/Projet-MM-IA/assets/89219090/c329e26a-e58d-4b87-9f77-2d63bd00cb4a)
![angry](https://github.com/asmakhoualdia98/Projet-MM-IA/assets/89219090/c0fa52bb-db14-481e-8bd4-579be73f60b5)
![sad](https://github.com/asmakhoualdia98/Projet-MM-IA/assets/89219090/a6bb8f65-7dcf-4c92-8e02-2a9f06970600)
![surprise](https://github.com/asmakhoualdia98/Projet-MM-IA/assets/89219090/cf3515a1-c388-468f-bb86-5aaa775af45d)

